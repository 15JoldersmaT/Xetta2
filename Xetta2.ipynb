{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "#All images follow this format Abstract_image_155\n",
    "#up to image 2781\n",
    "\n",
    "#batch size\n",
    "bs = 32\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b449c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnoise\u001b[39m(size):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable(torch\u001b[38;5;241m.\u001b[39mrandn(size, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenerator\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, z_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, out_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m):\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#not used\n",
    "img_size = 200\n",
    "\n",
    "print('test')\n",
    "def noise(size):\n",
    "    return Variable(torch.randn(size, 1*28*28))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=28*28, out_dim=28*28):\n",
    "        super().__init__()\n",
    "        print('Creating Generator ')\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, (28*28)*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #We want a 28*28 output\n",
    "            nn.Linear((28*28)*2, 28*28),\n",
    "            #We want an output of -1 to 1, Tanh() will work for this\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    #z_dim must match the output of the generator, in this case 28*28\n",
    "    def __init__(self, z_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(z_dim, 28*28*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(28*28*2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dis(x)  \n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, discriminator, generator, batch_size=32):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define binary cross entropy loss\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        # Define separate optimizers for discriminator and generator\n",
    "        self.d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "        self.g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002)\n",
    "\n",
    "    def train(self, num_epochs, dataloader):\n",
    "        # Training Loop for each epoch\n",
    "        print ('Starting')\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                # Generate images from noise, using the generator network.\n",
    "                sample_vectors = noise(64)\n",
    "                samples = generator(sample_vectors)\n",
    "                print(samples.shape)  # add print statement to check the shape of samples\n",
    "                samples = samples.view(64, 1, 28, 28) # reshape to (batch_size, channels, height, width)\n",
    "                print(samples.shape)  # add print statement to check the shape of samples after reshaping\n",
    "                \n",
    "                #CHANGE TO THE DIRECTORY YOU WANT\n",
    "                save_image(samples, f'martmine/output_{epoch}.png', normalize=True)\n",
    "            # Batch Loop for each set of images and labels\n",
    "            for n, (images, _) in enumerate(dataloader):\n",
    "                \n",
    "                # Prepare real images and real labels\n",
    "                real_images = Variable(images.view(images.size(0), -1))\n",
    "                real_labels = Variable(torch.ones(self.batch_size, 1))\n",
    "\n",
    "                # Train Discriminator on real images\n",
    "                self.d_optimizer.zero_grad()\n",
    "                real_outputs = self.discriminator(real_images)\n",
    "                d_loss_real = self.loss(real_outputs, real_labels)\n",
    "                d_loss_real.backward()\n",
    "                \n",
    "                # Prepare fake images and fake labels\n",
    "                noise_vectors = noise(self.batch_size)\n",
    "                fake_images = self.generator(noise_vectors)\n",
    "                fake_labels = Variable(torch.zeros(self.batch_size, 1))\n",
    "\n",
    "                # Train Discriminator on fake images\n",
    "                fake_outputs = self.discriminator(fake_images)\n",
    "                d_loss_fake = self.loss(fake_outputs, fake_labels)\n",
    "                d_loss_fake.backward()\n",
    "\n",
    "                # Update Discriminator weights\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Train Generator to fool the Discriminator\n",
    "                self.g_optimizer.zero_grad()\n",
    "                noise_vectors = noise(self.batch_size)\n",
    "                fake_images = self.generator(noise_vectors)\n",
    "                outputs = self.discriminator(fake_images)\n",
    "                \n",
    "                # We train the generator to generate images that the discriminator will think are real\n",
    "                g_loss = self.loss(outputs, Variable(torch.ones(self.batch_size, 1)))\n",
    "                g_loss.backward()\n",
    "\n",
    "                # Update Generator weights\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                if (n+1) % 1 == 0:\n",
    "                    print(f'Epoch {epoch+1}/{num_epochs}, Step {n+1}, d_loss: {d_loss_real+d_loss_fake}, g_loss: {g_loss}')\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "gan = GAN(discriminator, generator)\n",
    "gan.train(2000, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859f4c0",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
